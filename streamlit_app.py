"""
CortexX - Enterprise Sales Forecasting Dashboard
Main Streamlit application with robust date column detection.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import sys
import os
import logging
from typing import Optional, Dict, Any

# Add src to path with better error handling
src_path = os.path.join(os.path.dirname(__file__), 'src')
if src_path not in sys.path:
    sys.path.append(src_path)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Page configuration
st.set_page_config(
    page_title="CortexX - Sales Forecasting",
    page_icon="ðŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

class DataCollector:
    """Mock DataCollector for demonstration"""
    def load_csv_data(self, file):
        return pd.read_csv(file)
    
    def generate_sample_data(self, periods=365, products=3):
        dates = pd.date_range(start='2020-01-01', periods=periods, freq='D')
        data = []
        for date in dates:
            for product_id in range(1, products + 1):
                base_sales = 100 + product_id * 20
                seasonal = 50 * np.sin(2 * np.pi * date.dayofyear / 365)
                trend = 0.1 * (date - dates[0]).days
                noise = np.random.normal(0, 10)
                sales = max(0, base_sales + seasonal + trend + noise)
                data.append({
                    'date': date,
                    'product_id': product_id,
                    'sales': sales,
                    'price': 10 + product_id * 2
                })
        return pd.DataFrame(data)

class DataPreprocessor:
    """Mock DataPreprocessor"""
    pass

class DataExplorer:
    """Mock DataExplorer"""
    pass

class FeatureEngineer:
    """Mock FeatureEngineer"""
    def create_time_features(self, df, date_col):
        df = df.copy()
        if date_col in df.columns:
            df['year'] = df[date_col].dt.year
            df['month'] = df[date_col].dt.month
            df['day'] = df[date_col].dt.day
            df['day_of_week'] = df[date_col].dt.dayofweek
            df['quarter'] = df[date_col].dt.quarter
        return df
    
    def create_lag_features(self, df, value_col, lags):
        df = df.copy()
        for lag in lags:
            df[f'lag_{lag}'] = df[value_col].shift(lag)
        return df
    
    def create_rolling_features(self, df, value_col, windows):
        df = df.copy()
        for window in windows:
            df[f'rolling_mean_{window}'] = df[value_col].rolling(window=window).mean()
            df[f'rolling_std_{window}'] = df[value_col].rolling(window=window).std()
        return df
    
    def encode_cyclical_features(self, df):
        df = df.copy()
        if 'month' in df.columns:
            df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
            df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        if 'day_of_week' in df.columns:
            df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
            df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        return df

class FeatureSelector:
    """Mock FeatureSelector"""
    pass

class ModelTrainer:
    """Mock ModelTrainer with all required methods"""
    def train_test_split(self, df, date_col, target_col, test_size=0.2):
        if date_col != 'index':
            df = df.sort_values(date_col)
        split_idx = int(len(df) * (1 - test_size))
        return df.iloc[:split_idx], df.iloc[split_idx:]
    
    def train_xgboost(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "XGBoost_Model", results
    
    def train_lightgbm(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "LightGBM_Model", results
    
    def train_random_forest(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "RandomForest_Model", results
    
    def train_catboost(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "CatBoost_Model", results
    
    def train_lasso(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "Lasso_Model", results
    
    def train_ridge(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "Ridge_Model", results
    
    def train_decision_tree(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "DecisionTree_Model", results
    
    def train_knn(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "KNN_Model", results
    
    def train_svr(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "SVR_Model", results
    
    def train_ensemble(self, train_df, test_df, date_col, target_col):
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        # Mock implementation
        y_pred = np.random.normal(test_df[target_col].mean(), test_df[target_col].std(), len(test_df))
        rmse = np.sqrt(mean_squared_error(test_df[target_col], y_pred))  # Fixed: calculate RMSE manually
        results = {
            'RMSE': rmse,
            'MAE': mean_absolute_error(test_df[target_col], y_pred),
            'R2': r2_score(test_df[target_col], y_pred)
        }
        return "Ensemble_Model", results

class ModelEvaluator:
    """Mock ModelEvaluator"""
    def generate_evaluation_report(self, model_results):
        comparison_data = []
        for model_name, results in model_results.items():
            comparison_data.append({
                'Model': model_name,
                'RMSE': results.get('RMSE', 0),
                'MAE': results.get('MAE', 0),
                'R2': results.get('R2', 0)
            })
        
        # Find best model based on RMSE
        if comparison_data:
            best_model = min(comparison_data, key=lambda x: x['RMSE'])['Model']
        else:
            best_model = "No valid model found"
        
        return {
            'model_comparison': comparison_data,
            'best_model': best_model,
            'recommendations': [
                "Use ensemble methods for better accuracy",
                "Consider feature engineering for seasonal patterns",
                "Monitor model performance regularly"
            ]
        }

class VisualizationEngine:
    """Mock VisualizationEngine"""
    pass

class CortexXDashboard:
    """
    Main dashboard class for CortexX sales forecasting platform.
    """
    
    def __init__(self):
        """Initialize dashboard with all necessary components."""
        self.data_collector = DataCollector()
        self.preprocessor = DataPreprocessor()
        self.explorer = DataExplorer()
        self.feature_engineer = FeatureEngineer()
        self.feature_selector = FeatureSelector()
        self.model_trainer = ModelTrainer()
        self.model_evaluator = ModelEvaluator()
        self.visualizer = VisualizationEngine()
        
        # Initialize session state
        if 'data_loaded' not in st.session_state:
            st.session_state.data_loaded = False
        if 'current_data' not in st.session_state:
            st.session_state.current_data = None
        if 'features_created' not in st.session_state:
            st.session_state.features_created = False
        if 'models_trained' not in st.session_state:
            st.session_state.models_trained = False
        if 'date_column' not in st.session_state:
            st.session_state.date_column = None
        if 'value_column' not in st.session_state:
            st.session_state.value_column = None
    
    def run(self):
        """Run the main dashboard application."""
        try:
            # Header
            st.title("ðŸš€ CortexX - Enterprise Sales Forecasting Platform")
            st.markdown("---")
            
            # Sidebar navigation
            self._render_sidebar()
            
            # Main content based on selection
            self._render_content()
            
        except Exception as e:
            logger.error(f"Error running dashboard: {str(e)}")
            st.error(f"An error occurred: {str(e)}")
    
    def _render_sidebar(self):
        """Render the sidebar navigation."""
        st.sidebar.title("ðŸ“Š Navigation")
        
        # App mode selection
        self.app_mode = st.sidebar.selectbox(
            "Select Module",
            [
                "ðŸ  Dashboard Overview",
                "ðŸ“ Data Management", 
                "ðŸ” EDA & Analysis",
                "âš™ï¸ Feature Engineering",
                "ðŸ¤– Model Training",
                "ðŸ“ˆ Forecasting",
                "ðŸ“Š Results & Reports"
            ]
        )
        
        st.sidebar.markdown("---")
        st.sidebar.info("ðŸ’¡ **Tip**: Start with Data Management to upload your sales data.")
        
        # Data info panel
        if st.session_state.data_loaded and st.session_state.current_data is not None:
            st.sidebar.success("âœ… Data Loaded")
            data_shape = st.session_state.current_data.shape
            st.sidebar.write(f"**Records:** {data_shape[0]}")
            st.sidebar.write(f"**Features:** {data_shape[1]}")
            if st.session_state.date_column:
                st.sidebar.write(f"**Date Column:** {st.session_state.date_column}")
            if st.session_state.value_column:
                st.sidebar.write(f"**Value Column:** {st.session_state.value_column}")
    
    def _render_content(self):
        """Render main content based on selected mode."""
        if self.app_mode == "ðŸ  Dashboard Overview":
            self._render_dashboard_overview()
        elif self.app_mode == "ðŸ“ Data Management":
            self._render_data_management()
        elif self.app_mode == "ðŸ” EDA & Analysis":
            self._render_eda_analysis()
        elif self.app_mode == "âš™ï¸ Feature Engineering":
            self._render_feature_engineering()
        elif self.app_mode == "ðŸ¤– Model Training":
            self._render_model_training()
        elif self.app_mode == "ðŸ“ˆ Forecasting":
            self._render_forecasting()
        elif self.app_mode == "ðŸ“Š Results & Reports":
            self._render_results_reports()
    
    def _render_dashboard_overview(self):
        """Render dashboard overview section."""
        st.header("ðŸ  Dashboard Overview")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            ### Welcome to CortexX!
            
            **CortexX** is an enterprise-grade sales forecasting platform that helps businesses:
            
            - ðŸ“ˆ Predict future sales and demand accurately
            - ðŸ“Š Analyze historical trends and patterns  
            - ðŸ¤– Leverage advanced machine learning models
            - âš¡ Make data-driven inventory and staffing decisions
            
            ### Smart Data Detection:
            - **Automatic date column detection** from column names and content
            - **Flexible date format support** (YYYY-MM-DD, MM/DD/YYYY, etc.)
            - **Robust data validation** and quality checks
            - **Multiple forecasting models** (XGBoost, LightGBM, Ensemble)
            
            ### Quick Start Guide:
            1. **Data Management**: Upload your sales data or generate sample data
            2. **EDA & Analysis**: Explore patterns and correlations in your data
            3. **Feature Engineering**: Create advanced time-series features
            4. **Model Training**: Train and compare multiple forecasting models
            5. **Forecasting**: Generate future predictions and download results
            """)
        
        with col2:
            st.info("ðŸš€ **Get Started**: Upload your data in the Data Management section!")
            
            st.metric("Platform Status", "Operational", delta="Ready")
            st.metric("Auto Date Detection", "âœ… Enabled", delta="Smart")
            st.metric("Data Compatibility", "CSV, Excel", delta="Flexible")
        
        # System status
        st.subheader("ðŸ”§ System Status")
        status_cols = st.columns(4)
        
        with status_cols[0]:
            st.info("**Data Module** âœ… Ready")
        with status_cols[1]:
            st.info("**Date Detection** âœ… Smart")
        with status_cols[2]:
            st.info("**ML Engine** âœ… Ready")
        with status_cols[3]:
            st.info("**Dashboard** âœ… Ready")
    
    def _render_data_management(self):
        """Render data management section."""
        st.header("ðŸ“ Data Management")
        
        tab1, tab2, tab3 = st.tabs(["ðŸ“¤ Upload Data", "ðŸŽ² Generate Sample", "ðŸ” Data Preview"])
        
        with tab1:
            self._handle_data_upload()
        
        with tab2:
            self._handle_sample_data()
        
        with tab3:
            self._render_data_preview()
    
    def _handle_data_upload(self):
        """Handle file upload functionality."""
        st.subheader("Upload Your Sales Data")
        
        uploaded_file = st.file_uploader(
            "Choose a CSV file", 
            type=['csv'],
            help="Upload your sales data. Date columns will be automatically detected!"
        )
        
        if uploaded_file is not None:
            try:
                # Load data
                df = self.data_collector.load_csv_data(uploaded_file)
                
                # Basic validation
                if df.empty:
                    st.error("Uploaded file is empty.")
                    return
                
                # Auto-detect date and value columns
                date_cols = self._detect_date_columns(df)
                value_cols = self._detect_value_columns(df)
                
                # Store in session state
                st.session_state.current_data = df
                st.session_state.data_loaded = True
                
                # Set default columns
                if date_cols:
                    st.session_state.date_column = date_cols[0]
                if value_cols:
                    st.session_state.value_column = value_cols[0]
                
                st.success(f"âœ… Data loaded successfully! Shape: {df.shape}")
                
                # Show detection results
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Rows", df.shape[0])
                with col2:
                    st.metric("Columns", df.shape[1])
                with col3:
                    date_count = len(date_cols)
                    st.metric("Date Columns", date_count, delta="Auto-detected" if date_count > 0 else "None")
                
                # Show detected columns
                if date_cols:
                    st.info(f"ðŸ“… **Auto-detected date columns:** {', '.join(date_cols)}")
                if value_cols:
                    st.info(f"ðŸ“Š **Auto-detected value columns:** {', '.join(value_cols[:5])}")  # Show first 5
                
                # Allow manual column selection if auto-detection is uncertain
                if not date_cols or not value_cols:
                    st.warning("âš ï¸ Automatic column detection needs confirmation")
                    self._manual_column_selection(df, date_cols, value_cols)
                
            except Exception as e:
                st.error(f"Error loading data: {str(e)}")
                logger.error(f"Data upload error: {str(e)}")
    
    def _detect_date_columns(self, df: pd.DataFrame) -> list:
        """Detect date columns in the dataframe."""
        # Find datetime columns
        date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
        
        # Also check object columns that might contain dates
        object_cols = df.select_dtypes(include=['object']).columns
        for col in object_cols:
            if any(keyword in col.lower() for keyword in ['date', 'time', 'day', 'month', 'year']):
                # Try to convert
                try:
                    converted = pd.to_datetime(df[col], errors='coerce')
                    if not converted.isna().all():  # If conversion worked for most values
                        df[col] = converted
                        date_cols.append(col)
                except:
                    continue
        
        return date_cols
    
    def _detect_value_columns(self, df: pd.DataFrame) -> list:
        """Detect numerical value columns suitable for forecasting."""
        # Get numeric columns
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        # Filter out likely ID columns and constant columns
        value_cols = []
        for col in numeric_cols:
            # Skip if looks like an ID (low variance, integer values)
            if df[col].nunique() > len(df) * 0.1:  # More than 10% unique values
                value_cols.append(col)
            elif 'sales' in col.lower() or 'revenue' in col.lower() or 'amount' in col.lower():
                value_cols.append(col)  # Always include sales-like columns
        
        return value_cols if value_cols else numeric_cols
    
    def _manual_column_selection(self, df: pd.DataFrame, auto_date_cols: list, auto_value_cols: list):
        """Allow manual column selection when auto-detection is uncertain."""
        st.subheader("ðŸ”§ Manual Column Selection")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Date column selection
            all_cols = df.columns.tolist()
            date_col = st.selectbox(
                "Select date column (or index if no dates):",
                ['index'] + all_cols,
                index=0 if not auto_date_cols else all_cols.index(auto_date_cols[0]) + 1
            )
            
            if date_col != 'index':
                # Try to convert selected column to datetime
                try:
                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                    if df[date_col].isna().all():
                        st.warning(f"Column '{date_col}' doesn't contain valid dates")
                    else:
                        st.session_state.date_column = date_col
                except:
                    st.warning(f"Could not convert '{date_col}' to dates")
        
        with col2:
            # Value column selection
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                value_col = st.selectbox(
                    "Select value column to forecast:",
                    numeric_cols,
                    index=0 if not auto_value_cols else numeric_cols.index(auto_value_cols[0])
                )
                st.session_state.value_column = value_col
            else:
                st.error("No numeric columns found for forecasting")
        
        if st.button("âœ… Confirm Column Selection"):
            st.success("Columns confirmed! Proceed to analysis.")
            st.rerun()
    
    def _handle_sample_data(self):
        """Handle sample data generation."""
        st.subheader("Generate Sample Data")
        
        st.markdown("""
        Generate realistic sample sales data for testing and demonstration.
        The data includes trends, seasonality, and promotional effects.
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            periods = st.slider("Number of days", 30, 1095, 365)
        
        with col2:
            products = st.selectbox("Number of products", [1, 3, 5, 10], index=1)
        
        if st.button("ðŸŽ² Generate Sample Data", type="primary"):
            with st.spinner("Generating sample data..."):
                try:
                    sample_data = self.data_collector.generate_sample_data(
                        periods=periods, 
                        products=products
                    )
                    
                    st.session_state.current_data = sample_data
                    st.session_state.data_loaded = True
                    st.session_state.date_column = 'date'
                    st.session_state.value_column = 'sales'
                    
                    st.success(f"âœ… Sample data generated! Shape: {sample_data.shape}")
                    st.dataframe(sample_data.head(10), width='stretch')
                    
                except Exception as e:
                    st.error(f"Error generating sample data: {str(e)}")
    
    def _render_data_preview(self):
        """Render data preview section."""
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ Please upload or generate data first.")
            return
        
        df = st.session_state.current_data
        
        st.header("ðŸ“Š Data Preview")
        
        # Data overview
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Records", df.shape[0])
        with col2:
            st.metric("Total Features", df.shape[1])
        with col3:
            memory_usage = df.memory_usage(deep=True).sum() / 1024**2
            st.metric("Memory Usage", f"{memory_usage:.2f} MB")
        with col4:
            missing = df.isnull().sum().sum()
            st.metric("Missing Values", missing, delta="âš ï¸" if missing > 0 else "âœ…")
        
        # Column information
        st.subheader("ðŸ“‹ Column Information")
        col_info = pd.DataFrame({
            'Column': df.columns,
            'Data Type': [str(dtype) for dtype in df.dtypes],
            'Non-Null': df.count().values,
            'Null Count': df.isnull().sum().values,
            'Unique Values': df.nunique().values
        })
        st.dataframe(col_info, width='stretch')
        
        # Data tabs
        tab1, tab2, tab3 = st.tabs(["First 10 Rows", "Summary Statistics", "Data Types"])
        
        with tab1:
            st.dataframe(df.head(10), width='stretch')
        
        with tab2:
            st.dataframe(df.describe(), width='stretch')
        
        with tab3:
            # Show data type distribution
            dtype_counts = df.dtypes.value_counts()
            fig = px.pie(values=dtype_counts.values, names=dtype_counts.index.astype(str),
                        title="Data Type Distribution")
            st.plotly_chart(fig, use_container_width=True)
    
    def _render_eda_analysis(self):
        """Render EDA and analysis section."""
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ Please upload or generate data first.")
            return
        
        df = st.session_state.current_data
        
        st.header("ðŸ” Exploratory Data Analysis")
        
        # Column selection
        col1, col2 = st.columns(2)
        
        with col1:
            # Date column selection
            date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
            if not date_cols:
                st.error("""
                âŒ No date columns detected in the dataset.
                
                **Solutions:**
                1. Ensure your data has a date/time column
                2. Column names should contain words like 'date', 'time', 'day'
                3. Date formats supported: YYYY-MM-DD, MM/DD/YYYY, etc.
                4. Go back to Data Management to manually select columns
                """)
                return
            
            date_col = st.selectbox("Select date column", date_cols,
                                  index=date_cols.index(st.session_state.date_column) 
                                  if st.session_state.date_column in date_cols else 0)
            st.session_state.date_column = date_col
        
        with col2:
            # Value column selection
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if not numeric_cols:
                st.error("No numeric columns found for analysis")
                return
            
            value_col = st.selectbox("Select value column", numeric_cols,
                                   index=numeric_cols.index(st.session_state.value_column) 
                                   if st.session_state.value_column in numeric_cols else 0)
            st.session_state.value_column = value_col
        
        # EDA Tabs
        tab1, tab2, tab3, tab4 = st.tabs(["Trend Analysis", "Distributions", "Seasonality", "Correlations"])
        
        with tab1:
            self._render_trend_analysis(df, date_col, value_col)
        
        with tab2:
            self._render_distribution_analysis(df, value_col)
        
        with tab3:
            self._render_seasonality_analysis(df, date_col, value_col)
        
        with tab4:
            self._render_correlation_analysis(df)
    
    def _render_trend_analysis(self, df, date_col, value_col):
        """Render trend analysis visualizations."""
        st.subheader("ðŸ“ˆ Trend Analysis")
        
        # Convert to time series
        ts_df = df.set_index(date_col)[value_col]
        
        # Main trend plot
        fig_trend = px.line(df, x=date_col, y=value_col, 
                           title=f'{value_col} Trend Over Time',
                           template='plotly_white')
        st.plotly_chart(fig_trend, use_container_width=True)
        
        # Moving averages
        st.subheader("ðŸ“Š Moving Averages")
        col1, col2 = st.columns(2)
        
        with col1:
            window_7 = ts_df.rolling(window=7).mean()
            fig_ma7 = go.Figure()
            fig_ma7.add_trace(go.Scatter(x=window_7.index, y=window_7.values, 
                                       name='7-Day Moving Average'))
            fig_ma7.update_layout(title='7-Day Moving Average')
            st.plotly_chart(fig_ma7, use_container_width=True)
        
        with col2:
            window_30 = ts_df.rolling(window=30).mean()
            fig_ma30 = go.Figure()
            fig_ma30.add_trace(go.Scatter(x=window_30.index, y=window_30.values, 
                                        name='30-Day Moving Average'))
            fig_ma30.update_layout(title='30-Day Moving Average')
            st.plotly_chart(fig_ma30, use_container_width=True)
    
    def _render_distribution_analysis(self, df, value_col):
        """Render distribution analysis."""
        st.subheader("ðŸ“Š Distribution Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_hist = px.histogram(df, x=value_col, nbins=50,
                                  title=f'Distribution of {value_col}')
            st.plotly_chart(fig_hist, use_container_width=True)
        
        with col2:
            fig_box = px.box(df, y=value_col, title=f'Box Plot of {value_col}')
            st.plotly_chart(fig_box, use_container_width=True)
    
    def _render_seasonality_analysis(self, df, date_col, value_col):
        """Render seasonality analysis."""
        st.subheader("ðŸ”„ Seasonality Analysis")
        
        df_temp = df.copy()
        df_temp['month'] = df_temp[date_col].dt.month
        df_temp['day_of_week'] = df_temp[date_col].dt.dayofweek
        
        col1, col2 = st.columns(2)
        
        with col1:
            monthly_avg = df_temp.groupby('month')[value_col].mean().reset_index()
            fig_monthly = px.line(monthly_avg, x='month', y=value_col,
                                title='Monthly Seasonality')
            st.plotly_chart(fig_monthly, use_container_width=True)
        
        with col2:
            weekly_avg = df_temp.groupby('day_of_week')[value_col].mean().reset_index()
            fig_weekly = px.line(weekly_avg, x='day_of_week', y=value_col,
                               title='Weekly Seasonality')
            st.plotly_chart(fig_weekly, use_container_width=True)
    
    def _render_correlation_analysis(self, df):
        """Render correlation analysis."""
        st.subheader("ðŸ”— Correlation Analysis")
        
        numeric_df = df.select_dtypes(include=[np.number])
        
        if len(numeric_df.columns) > 1:
            corr_matrix = numeric_df.corr()
            fig_corr = px.imshow(corr_matrix, title="Correlation Matrix")
            st.plotly_chart(fig_corr, use_container_width=True)
        else:
            st.info("Not enough numeric columns for correlation analysis")
    
    def _render_feature_engineering(self):
        """Render feature engineering section."""
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ Please upload or generate data first.")
            return
        
        df = st.session_state.current_data
        
        st.header("âš™ï¸ Feature Engineering")
        
        st.markdown("""
        Create advanced time-series features to improve forecasting accuracy.
        """)
        
        # Feature engineering options
        col1, col2 = st.columns(2)
        
        with col1:
            create_time_features = st.checkbox("Create time-based features", value=True)
            create_lag_features = st.checkbox("Create lag features", value=True)
        
        with col2:
            create_rolling_features = st.checkbox("Create rolling features", value=True)
            encode_cyclical = st.checkbox("Encode cyclical features", value=True)
        
        if st.button("ðŸš€ Generate Features", type="primary"):
            with st.spinner("Creating advanced features..."):
                try:
                    # Apply feature engineering
                    engineered_df = df.copy()
                    
                    # Auto-detect date column
                    date_cols = engineered_df.select_dtypes(include=['datetime64']).columns.tolist()
                    if not date_cols:
                        for col in engineered_df.columns:
                            if 'date' in col.lower():
                                try:
                                    engineered_df[col] = pd.to_datetime(engineered_df[col])
                                    date_cols.append(col)
                                    break
                                except:
                                    continue
                    
                    if not date_cols:
                        st.error("No date column found for feature engineering.")
                        return
                    
                    date_col = date_cols[0]
                    
                    if create_time_features:
                        engineered_df = self.feature_engineer.create_time_features(engineered_df, date_col)
                    
                    # Get numeric columns for lag/rolling features
                    numeric_cols = engineered_df.select_dtypes(include=[np.number]).columns.tolist()
                    if numeric_cols:
                        value_col = st.selectbox(
                            "Select target column for lag/rolling features", 
                            numeric_cols, key="feature_target"
                        )
                        
                        if create_lag_features and value_col:
                            engineered_df = self.feature_engineer.create_lag_features(
                                engineered_df, value_col, [1, 7, 30]
                            )
                        
                        if create_rolling_features and value_col:
                            engineered_df = self.feature_engineer.create_rolling_features(
                                engineered_df, value_col, [7, 30]
                            )
                    
                    if encode_cyclical:
                        engineered_df = self.feature_engineer.encode_cyclical_features(engineered_df)
                    
                    # Update session state
                    st.session_state.current_data = engineered_df
                    st.session_state.features_created = True
                    
                    st.success(f"âœ… Features created successfully! New shape: {engineered_df.shape}")
                    
                except Exception as e:
                    st.error(f"Error in feature engineering: {str(e)}")
    
    def _render_model_training(self):
        """Render model training section."""
        if not st.session_state.data_loaded:
            st.warning("âš ï¸ Please upload or generate data first.")
            return
        
        df = st.session_state.current_data
        
        st.header("ðŸ¤– Model Training")
        
        st.markdown("""
        Train multiple forecasting models and compare their performance.
        """)
        
        # Model configuration
        AVAILABLE_MODELS = {
            "XGBoost": self.model_trainer.train_xgboost,
            "LightGBM": self.model_trainer.train_lightgbm,
            "RandomForest": self.model_trainer.train_random_forest,
            "CatBoost": self.model_trainer.train_catboost,
            "Lasso": self.model_trainer.train_lasso,
            "Ridge": self.model_trainer.train_ridge,
            "DecisionTree": self.model_trainer.train_decision_tree,
            "KNeighbors": self.model_trainer.train_knn,
            "SVR": self.model_trainer.train_svr,
            "Ensemble (Voting)": self.model_trainer.train_ensemble 
        }

        col1, col2 = st.columns(2)
        
        with col1:
            # Target selection
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if not numeric_cols:
                st.error("No numeric columns found for modeling.")
                return
            target_col = st.selectbox("Select target variable", numeric_cols, 
                                      index=numeric_cols.index(st.session_state.value_column) 
                                      if st.session_state.value_column in numeric_cols else 0)
            
            # Date column selection
            date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
            if not date_cols:
                st.warning("No date column found. Using index as time reference.")
                date_col = 'index'
            else:
                date_col = st.selectbox("Select date column", date_cols,
                                        index=date_cols.index(st.session_state.date_column)
                                        if st.session_state.date_column in date_cols else 0)
        
        with col2:
            models_to_train = st.multiselect(
                "Select models to train",
                list(AVAILABLE_MODELS.keys()),
                default=["XGBoost", "Lasso", "RandomForest", "LightGBM"]
            )
            
            # Train/test split
            test_size = st.slider("Test set size (%)", 10, 40, 20)
        
        if st.button("ðŸŽ¯ Train Models", type="primary"):
            with st.spinner("Training models... This may take a few minutes."):
                try:
                    # Prepare data for training
                    train_df, test_df = self.model_trainer.train_test_split(
                        df, date_col, target_col, test_size=test_size/100
                    )
                    
                    trained_models = {}
                    model_results = {}
                    
                    for model_name in models_to_train:
                        if model_name in AVAILABLE_MODELS:
                            st.write(f"Training {model_name}...")
                            
                            model_function = AVAILABLE_MODELS[model_name]
                            
                            model, results = model_function(
                                train_df, test_df, date_col, target_col
                            )
                        
                            if model is not None and results is not None:
                                trained_models[model_name] = model
                                model_results[model_name] = results
                            else:
                                st.error(f"Failed to train {model_name}")
                    
                    # Store in session state
                    st.session_state.trained_models = trained_models
                    st.session_state.model_results = model_results
                    st.session_state.models_trained = True
                    
                    st.success("âœ… Models trained successfully!")
                    
                except Exception as e:
                    st.error(f"Error training models: {str(e)}")

    def _render_forecasting(self):
        """Render forecasting section."""
        if not st.session_state.models_trained:
            st.warning("âš ï¸ Please train models first in the Model Training section.")
            return

        st.header("ðŸ“ˆ Forecasting")

        st.info("Forecasting module ready - model training completed successfully!")

        st.subheader("Generate Forecasts")

        col1, col2 = st.columns(2)

        with col1:
            forecast_days = st.slider("Forecast horizon (days)", 7, 90, 30)

        with col2:
            selected_model = st.selectbox(
                "Select model for forecasting",
                list(st.session_state.trained_models.keys())
            )

        # Generate forecasting
        if st.button("ðŸ”® Generate Forecast", type="primary") or "forecast_df" not in st.session_state:
            with st.spinner("Generating forecasts..."):
                try:
                    df = st.session_state.current_data
                    last_date = df[st.session_state.date_column].max()

                    # Generate fake forecast
                    future_dates = pd.date_range(
                        start=last_date + timedelta(days=1),
                        periods=forecast_days,
                        freq='D'
                    )
                    base_value = df[st.session_state.value_column].mean()
                    forecast_values = base_value * (1 + np.random.normal(0, 0.1, forecast_days))

                    forecast_df = pd.DataFrame({
                        'Date': future_dates,
                        'Forecast': forecast_values,
                        'Model': selected_model
                    })

                    # Store in session state to avoid reloading
                    st.session_state["forecast_df"] = forecast_df
                    st.session_state["historical_df"] = df
                    st.session_state["selected_model"] = selected_model

                    st.success(f"âœ… Forecast generated for {forecast_days} days!")

                except Exception as e:
                    st.error(f"Error generating forecast: {str(e)}")
                    return

        # Display forecast if available
        if "forecast_df" in st.session_state:
            forecast_df = st.session_state["forecast_df"]
            df = st.session_state["historical_df"]
            selected_model = st.session_state["selected_model"]

            st.subheader("ðŸ“Š Forecast Results")
            st.dataframe(forecast_df, width='stretch')

            # Slider for controlling the intervals of the graph
            min_date = df[st.session_state.date_column].min()
            max_date = forecast_df['Date'].max()

            if "forecast_slider" not in st.session_state:
                st.session_state["forecast_slider"] = (min_date.to_pydatetime(), max_date.to_pydatetime())

            st.slider(
                "ðŸ•’ Select date range to display",
                min_value=min_date.to_pydatetime(),
                max_value=max_date.to_pydatetime(),
                value=st.session_state["forecast_slider"],
                format="YYYY-MM-DD",
                key="forecast_slider"
            )

            time_range = st.session_state["forecast_slider"]

            df_filtered = df[
                (df[st.session_state.date_column] >= time_range[0]) &
                (df[st.session_state.date_column] <= time_range[1])
            ]
            forecast_filtered = forecast_df[
                (forecast_df['Date'] >= time_range[0]) &
                (forecast_df['Date'] <= time_range[1])
            ]

            # Plotting
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=df_filtered[st.session_state.date_column],
                y=df_filtered[st.session_state.value_column],
                name='Historical Data'
            ))
            fig.add_trace(go.Scatter(
                x=forecast_filtered['Date'],
                y=forecast_filtered['Forecast'],
                name=f'{selected_model} Forecast',
                line=dict(dash='dash')
            ))
            fig.update_layout(
                title=f'Sales Forecast - {selected_model}',
                xaxis_title="Date",
                yaxis_title="Value",
                hovermode="x unified"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Forecast Deviation Analysis
            st.subheader("ðŸ“‰ Forecast Deviation Analysis")

            # Calculate how much forecast differs from the mean value
            mean_value = df[st.session_state.value_column].mean()
            forecast_df["Deviation"] = ((forecast_df["Forecast"] - mean_value) / mean_value) * 100

            # Create deviation chart
            fig_dev = go.Figure()
            fig_dev.add_trace(go.Bar(
                x=forecast_df["Date"],
                y=forecast_df["Deviation"],
                name="Deviation (%)",
                marker_color="orange"
            ))
            fig_dev.add_shape(
                type="line",
                x0=forecast_df["Date"].min(),
                x1=forecast_df["Date"].max(),
                y0=0,
                y1=0,
                line=dict(color="black", width=1, dash="dot")
            )
            fig_dev.update_layout(
                title="Forecast Deviation from Mean Value (%)",
                xaxis_title="Date",
                yaxis_title="Deviation (%)",
                hovermode="x unified",
                showlegend=False
            )
            st.plotly_chart(fig_dev, use_container_width=True)
    
    def _render_results_reports(self):
        """Render results and reports section."""
        st.header("ðŸ“Š Results & Reports")
        
        if not st.session_state.models_trained:
            st.warning("âš ï¸ Please train models first to see results.")
            return
        
        st.success("âœ… Model training completed successfully!")
        
        st.subheader("ðŸ“ˆ Model Performance Comparison")
        
        try:
            model_results = st.session_state.model_results
            
            if not model_results:
                st.info("No models were trained successfully.")
                return

            report = self.model_evaluator.generate_evaluation_report(model_results)
            
            performance_df = pd.DataFrame(report['model_comparison'])
            
            if not performance_df.empty:
                st.dataframe(performance_df.style.highlight_min(subset=['RMSE', 'MAE'], color='lightgreen'), width='stretch')
                
                # Best model
                best_model_name = report['best_model']
                if best_model_name and best_model_name != 'No valid model found':
                    best_model_metrics = performance_df[performance_df['Model'] == best_model_name].iloc[0]
                    st.info(f"ðŸŽ¯ **Best Model**: {best_model_name} (RMSE: {best_model_metrics['RMSE']:.2f})")
                else:
                    st.warning("Could not determine best model (check for training errors or NaN values).")
            else:
                st.info("Performance metrics could not be calculated.")
                
        except Exception as e:
            st.error(f"Error displaying results: {str(e)}")
            logger.error(f"Error in results report: {e}")

        # Recommendations
        st.subheader("ðŸ’¡ Recommendations")
        if 'report' in locals() and report.get('recommendations'):
            for rec in report['recommendations']:
                 st.markdown(f"- {rec}")
        else:
            st.markdown("""
            - **Inventory Management**: Use forecasts to optimize stock levels
            - **Promotional Planning**: Schedule promotions during predicted high-demand periods  
            """)
        
        # Export report
        st.subheader("ðŸ“„ Export Report")
        if st.button("ðŸ“¤ Generate Comprehensive Report"):
            if 'performance_df' in locals():
                csv = performance_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="Download Report as CSV",
                    data=csv,
                    file_name="model_performance_report.csv",
                    mime="text/csv",
                )
                st.success("Report generated successfully!")
            else:
                st.error("No performance data to generate report.")


def main():
    """Main function to run the CortexX dashboard."""
    try:
        dashboard = CortexXDashboard()
        dashboard.run()
    except Exception as e:
        st.error(f"Failed to initialize dashboard: {str(e)}")

if __name__ == "__main__":
    main()